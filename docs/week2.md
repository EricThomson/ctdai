# Week 2: Retrieval-augmented generation (RAG)

RAG systems are basically LLMs that are turbo-charged with additional external data sources that go beyond their additional training. E.g., if you ask your LLM who won the World Cup, and it tells you an answer from 2018, then your LLM needs to be updated. 

Foundational LLMs are trained on the entire internet, with out-of-date information. You often  need more recent knowledge, domain-specific knowledge, or proprietary knowledge stored in documents or a database that needs to be continually updated. 

By connecting an LLM to a custom data store (such as a relational database, or a document store), this lets your LLM remain relevant in your particular use case without needing to retrain the model. LLMs that are are augmented with such supplementary knowledge stores are known as *RAG systems*, or sometimes knowledge augmented systems. 

## Focus
- 

## Hands-On Activities
- 

## Learning Outcomes
By the end of this week, students will be able to:


## Resources
- [RAG intro](https://aws.amazon.com/what-is/retrieval-augmented-generation/)
-

## Instructor Notes

